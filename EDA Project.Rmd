---
title: "EDA"
author: "Tyler Swanson"
date: "2024-09-28"
output:
  html_document:
    number_sections: no
    toc: yes
editor_options: 
  chunk_output_type: inline
  execute:
  warning: false
  message: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

**Business Problem**:
People often have a difficult time when it comes to getting loans due to a lack of credit history. This can lead to financial challenges and even result in loans being placed with unethical lenders. Home Credit Group is looking to solve this issue by providing a positive and safe borrowing experience to people that lack traditional credit history. One of Home Credit’s challenges is unlocking the full potential of their data to ensure their current system for predicting who can repay loans is accurate. Currently, some customers that should qualify for a loan are being wrongly rejected due to limitations in Home Credit Group’s system.

**Benefit of a solution**: 
If Home Credit Group can enhance their prediction system to more accurately assess a customer’s ability to repay loans, they will be able to offer ethical lending options to those in need. Unlocking the full potential of their data will also ensure that the loan terms and conditions they provide will empower their clients to be successful. 

**Success Metrics**:
1.	Increase the rate of approved loans for customers that can repay. The more qualified clients that work with Home Credit, the fewer loans that will be placed with unethical lenders. 
2.	Decrease loan default rates.
3.	Provide clients with loan terms and conditions that will empower their success.  

**Analytics Approach**: 
Use a supervised machine learning methods to improve Home Credit Group’s predictive power when determining the binary target variable of repayment ability. Since the goal is to determine if a client will be able to repay their loan or not, this is a classification problem of yes or no. 

**Scope**:
To goal of this project is to create a better model to predict if a client will be able to repay their loan and to provide better information on loan terms that will empower their client’s success. 

**Details**: 
This project will be completed by an individual MABA student over the 2024 Fall Semester. The project will be finished before January 2025. Important milestones will be Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment. 

**Target Variable**: TARGET - target variable (1 - client with payment difficulties: he/she had late payment more than X days on at least one of the first Y installments of the loan in our sample, 0 - all other cases)

**Guiding Questions**: 
1. What is the distribution of the target variable?
2. Which numerical variables have the strongest correlations with the target variable?
3. How do categorical variables relate to the target variable?
4. How much missing data is present, and is there a pattern to it?
5. Are there any significant outliers or anomalies in the data?
6. How does repayment behavior change over time?
7. Which groups of clients are most likely to default?
8. How do external data sources impact repayment predictions?
9. Which features are most important for predicting the target variable?

# Load packages & import data
```{r load packages & import data}

# Load library
if (!requireNamespace("dplyr", quietly = TRUE)) {
  install.packages("dplyr")
}
library(dplyr)

if (!requireNamespace("ggplot2", quietly = TRUE)) {
  install.packages("ggplot2")
}
library(ggplot2)


# Import data
mydir <- getwd()
setwd(mydir)

application_test <- read.csv("application_test.csv", stringsAsFactors = FALSE)

application_train <- read.csv("application_train.csv", stringsAsFactors = FALSE)

bureau <- read.csv("bureau.csv", stringsAsFactors = FALSE)

previous_application <- read.csv("previous_application.csv", stringsAsFactors = FALSE)

HomeCredit_data_dictionary <- read.csv("HomeCredit_columns_description.csv", stringsAsFactors = FALSE)

```

# Exploratory data analysis tables
```{r exploratory data analysis}
# Explore application_train
str(application_train)
# summary(application_train)
# head(application_train)

# Explore application_test
str(application_test)
# summary(application_test)
# head(application_test)

# Explore bureau 
str(bureau)
# summary(bureau)
# head(bureau)

# Explore previous_application
str(previous_application)
# summary(previous_application)
# head(previous_application)

# Explore HomeCredit_data_dictionary
# view(HomeCredit_data_dictionary)
head(HomeCredit_data_dictionary)

```

# Tasks

## Exploring the target variable in application_train

The target variable analysis shows that 91.9% of clients have no payment difficulties with repayment, while 8.1% of clients have payment difficulties, this shows a highly imbalanced dataset. This imbalance suggests that a model predicting only the majority class will achieve an accuracy of 91.9%, but it will fail to effectively identify clients with payment difficulties.

```{r explore target variable in application_train}

# TARGET: Target variable (1 - client with payment difficulties: he/she had late payment more than X days on at least one of the first Y installments of the loan in our sample, 0 - all other cases)

# Explore the target variable in the training data
table(application_train$TARGET)

# Calculate the proportion for each class
target_distribution <- application_train %>%
  group_by(TARGET) %>%
  summarise(count = n()) %>%
  mutate(percentage = count / sum(count) * 100)

# Distribution
print(target_distribution)

# Distribution plot
ggplot(target_distribution, aes(factor(TARGET), percentage, fill = factor(TARGET))) +
  geom_bar(stat = "identity") +
  labs(title = "Target Variable Distribution", x = "Target", y = "Percentage") 

# Data balance 
is_unbalanced <- max(target_distribution$percentage) > 50
print(paste("The target variable is unbalanced:", is_unbalanced))

# Majority class accuracy
majority_class_percentage <- max(target_distribution$percentage) / 100

print(paste("Majority class classifier =", round(majority_class_percentage * 100, 2), "%"))
```

## Explore the relationship between target and predictors

The analysis of the relationship between the target variable and predictors identifies the top 5 predictors most correlated with the target variable. External source data is the top 3 predictors followed by DAYS_BIRTH and REGION_RATING_CLIENT_W_CITY. The strongest correlations are relatively weak, with absolute values below 0.2. This indicates that individual predictors might have limited predictive power on their own which suggests that while no single predictor is highly influential. When looking at the relationship between categorical variables and the target variable, most categorical variables did not show a significant impact on clients having payment difficulties. However, NAME_INCOME_TYPE did show that Maternity leave and Unemployed clients have a relatively higher proportion of payment difficulties.

```{r Explore relationship between target and predictors}

# Remove non-predictive SK_ID_CURR column
# application_train_clean <- application_train %>% select(-SK_ID_CURR)
application_train_clean <- application_train

# Split up numeric and categorical columns
numeric_vars <- application_train_clean %>% select(where(is.numeric)) %>% select(-TARGET)
categorical_vars <- application_train_clean %>% select(where(is.character))

# Check target and numeric correlation
correlation_with_target <- sapply(numeric_vars, function(x) cor(application_train_clean$TARGET, x, use = "complete.obs"))

# Convert correlation result to a data frame
correlation_df <- data.frame(variable = names(correlation_with_target), 
                             correlation = correlation_with_target)

# Top 5 predictors with the strongest correlation
top_predictors <- correlation_df %>%
  arrange(desc(abs(correlation))) %>%
  head(5)

print("Top Predictors:")
print(top_predictors)

# Visualize correlations
ggplot(top_predictors, aes(x = reorder(variable, abs(correlation)), y = correlation)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Top 5 Predictors with Strongest Correlation to Target",
       x = "Predictor Variables",
       y = "Correlation with Target") +
  theme_minimal()


# Plot relationships between target and top numeric predictors
for (variable in top_predictors$variable) {
  plot_numeric_relationship <- ggplot(application_train_clean, aes_string(x = variable, 
    fill = as.factor(application_train_clean$TARGET))) +
    geom_density(alpha = 0.5) +
    labs(title = paste("Distribution of", variable, "by Target"),
         x = variable, fill = "Target") +
    theme_minimal() +
    theme(legend.position = "bottom") +
    scale_fill_manual(values = c("red", "blue"))
  
  print(plot_numeric_relationship)
}

# NAME_INCOME_TYPE and TARGET relationship
NAME_INCOME_TYPE_Data <- table(application_train$NAME_INCOME_TYPE, application_train$TARGET)

# proportion conversion
conversion_prop_table <- prop.table(NAME_INCOME_TYPE_Data, margin = 1)

# ggplot data frame
prop_table_df <- as.data.frame(conversion_prop_table)
colnames(prop_table_df) <- c("NAME_INCOME_TYPE", "Target", "Proportion")

# Plot NAME_INCOME_TYPE and TARGET relationship
plot_income_vs_target <- ggplot(prop_table_df, aes(x = NAME_INCOME_TYPE, y = Proportion, fill = factor(Target))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Relationship between NAME_INCOME_TYPE and Target",
       x = "Income Type", y = "Proportion",
       fill = "Target") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Display plot
print(plot_income_vs_target)


```

## skimr

When running skimr on  application_train_clean and application_test to highlight potential data issues, we can see that OWN_CAR_AGE has 202,929 missing values in application_train_clean and 32,312 missing values in application_test. OCCUPATION_TYPE, FONDKAPREMONT_MODE, HOUSETYPE_MODE, WALLSMATERIAL_MODE, and EMERGENCYSTATE_MODE also have substantial missing values. There are also multiple variables with outlines, for example, AMT_INCOME_TOAL has a max value of 117,000,000 in application_train_clean which suggests the presence of extreme outliers. We also get insight on negative values. Skimr highlights DAYS_BIRTH as a negative which is okay because based on the data dictionary we know that Client's age in days at the time of application, however DAYS_EMPLOYED contains negative values that don't make sense because DAYS_EMPLOYED is the number of days before the application the person started current employment. 
```{r skimr}
if (!requireNamespace("skimr", quietly = TRUE)) {
  install.packages("skimr")
}

# Load skimr
library(skimr)

# Use skim() to get a detailed summary of your data
skim(application_train_clean)
# skim(application_test)

```

## Explore scope of missing data and clean it.

During the data cleaning process, 122 columns with more than 80% missing values were removed from the training set. The test set did not have any columns with more than 80% missing values so none were removed. There were not any duplicate rows found and empty rows and columns were removed. Missing numbers were input using median values and categorical variables were filled with their respective mode values. This clean process resulted in a more usable dataset with 83 columns in the training data and 93 columns in the test data. 

```{r explore scope of missing data}
# ---------------------------
# Data Cleaning and Preparation
# ---------------------------

# Load required packages
library(janitor)
library(tidyr)
library(skimr)

# ---------------------------
# Step 1: Clean Column Names and Remove Empty Rows/Columns
# ---------------------------
application_train_clean <- application_train_clean %>%
  clean_names() %>%                 # Clean column names
  remove_empty("rows") %>%          # Remove empty rows
  remove_empty("cols")              # Remove empty columns

# ---------------------------
# Step 2: Handle Duplicates
# ---------------------------

# Check for duplicate rows
duplicates <- get_dupes(application_train_clean)
print(duplicates)

# Remove exact duplicates
application_train_clean <- application_train_clean %>% distinct()

# ---------------------------
# Step 3: Summarize Missing Data
# ---------------------------

# Summarize missing data for the training dataset
train_missing_summary <- application_train_clean %>%
  summarize_all(~sum(is.na(.))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "missing_count") %>%
  mutate(missing_percentage = (missing_count / nrow(application_train_clean)) * 100) %>%
  arrange(desc(missing_percentage))

# Display variables with the most missing data in the training set
print("Missing data in application_train:")
head(train_missing_summary, 10)

# ---------------------------
# Step 4: Remove Columns with > 80% Missing Values
# ---------------------------

# Identify columns with more than 80% missing data
high_missing_train <- train_missing_summary %>% filter(missing_percentage > 80)

# Remove columns with > 80% missing values
application_train_clean <- application_train_clean %>%
  select(-one_of(high_missing_train$variable))

# Review removed columns
removed_columns_train <- setdiff(names(application_train), names(application_train_clean))
print(paste("Columns removed from training dataset:", length(removed_columns_train)))

# ---------------------------
# Step 5: Count Missing Values in Key External Source Variables
# ---------------------------

# Count the number of missing values in ext_source_1, ext_source_2, ext_source_3 for training dataset
missing_train_ext_sources <- colSums(is.na(application_train_clean[, c("ext_source_1", "ext_source_2", "ext_source_3")]))
print("Missing values in training dataset (ext_source variables):")
print(missing_train_ext_sources)

# ---------------------------
# Step 6: Impute Missing Values
# ---------------------------

# Impute missing values for numeric variables (excluding ext_source variables)
numeric_vars_train <- application_train_clean %>% select(where(is.numeric))
exclude_vars <- c("ext_source_1", "ext_source_2", "ext_source_3")

for (variable in names(numeric_vars_train)) {
  if (!(variable %in% exclude_vars)) {
    application_train_clean[[variable]][is.na(application_train_clean[[variable]])] <- median(application_train_clean[[variable]], na.rm = TRUE)
  }
}

# Impute missing values for categorical variables
categorical_vars_train <- application_train_clean %>% select(where(is.character))

for (variable in names(categorical_vars_train)) {
  update_value_train <- names(sort(table(application_train_clean[[variable]]), decreasing = TRUE))[1]
  application_train_clean[[variable]][is.na(application_train_clean[[variable]])] <- update_value_train
}


# ---------------------------
# Step 8: Identify and Drop Highly Correlated Variables
# ---------------------------

# Create a correlation matrix for numeric variables
cor_matrix <- application_train_clean %>%
  select(where(is.numeric)) %>%
  cor(use = "complete.obs")

# Find highly correlated variable pairs (threshold > 0.8)
highly_correlated_pairs <- as.data.frame(as.table(cor_matrix)) %>%
  filter(abs(Freq) > 0.8 & Var1 != Var2) %>%
  arrange(desc(abs(Freq)))

# Display highly correlated pairs
print("Highly correlated variable pairs:")
print(highly_correlated_pairs)

# Identify variables to drop (Var2 from highly correlated pairs)
variables_to_drop <- unique(highly_correlated_pairs$Var2)

# Drop the identified highly correlated variables from the dataset
application_train_clean <- application_train_clean %>% select(-one_of(variables_to_drop))

# Verify the variables have been removed
print(paste("Dropped variables:", variables_to_drop))
str(application_train_clean)

# ---------------------------
# Step 9: Dataset Summary
# ---------------------------

# Summary of the cleaned training dataset
skim(application_train_clean)

# Display the values in ext_source_1, ext_source_2, and ext_source_3
ext_source_values <- application_train_clean %>% select(ext_source_1, ext_source_2, ext_source_3)

# Display the first few rows of the selected values
head(ext_source_values)

# ---------------------------
# Step 10: Remove Outliers
# ---------------------------

# Loop over all numeric variables and apply the 99th percentile filter
numeric_vars <- application_train_clean %>%
  select_if(is.numeric) %>%
  names()

# Iterate through each numeric variable and filter out the top 1% outliers
for (var in numeric_vars) {
  # Calculate the 99th percentile for the current variable
  percentile_99 <- quantile(application_train_clean[[var]], 0.99, na.rm = TRUE)
  
  # Filter out the top 1% outliers for the current variable
  application_train_clean <- application_train_clean %>%
    filter(!!sym(var) <= percentile_99)
}

# Display the top 10 values for each numeric variable in the cleaned dataset
# for (var in numeric_vars) {
# cat("\nTop 10 values for", var, "after removing outliers:\n")
# top_10_values <- application_train_clean_no_outliers %>%
#    arrange(desc(!!sym(var))) %>%
#    select(!!sym(var)) %>%
#    head(10)
  
#  print(top_10_values)
# }

```

## Transform data

The data from bureau.csv and previous_application.csv were aggregated by SK_ID_CURR to calculate metrics like the number of records, average active credit, total credit amount, and average days since credit for each applicant. These aggregated features were then merged with application_train.csv and application_test.csv to enhance the main datasets with additional insights about the applicants' credit history and previous applications.

```{r transform data}
#Aggregate bureau.csv and SK_ID_CURR
bureau_aggregated <- bureau %>%
  group_by(SK_ID_CURR) %>%
  summarize(
    bureau_count = n(), 
    avg_credit_active = mean(CREDIT_ACTIVE == "Active", na.rm = TRUE), 
    total_credit_amt = sum(AMT_CREDIT_SUM, na.rm = TRUE), 
    avg_days_credit = mean(DAYS_CREDIT, na.rm = TRUE) 
  )

# Aggregate previous_application.csv and SK_ID_CURR
previous_application_aggregated <- previous_application %>%
  group_by(SK_ID_CURR) %>%
  summarize(
    prev_app_count = n(), # Number of previous applications per applicant
    avg_credit_approved = mean(NAME_CONTRACT_STATUS == "Approved", na.rm = TRUE), # Proportion of approved applications
    max_amt_credit = max(AMT_CREDIT, na.rm = TRUE), # Maximum credit amount in previous applications
    avg_amt_credit = mean(AMT_CREDIT, na.rm = TRUE) # Average credit amount
  )

# Conditionally rename 'sk_id_curr' to 'SK_ID_CURR' if 'sk_id_curr' exists in application_train_clean
if ("sk_id_curr" %in% colnames(application_train_clean)) {
  application_train_clean <- application_train_clean %>%
    rename(SK_ID_CURR = sk_id_curr)
}

# Aggregate the bureau_aggregated data by SK_ID_CURR
# bureau_aggregated_unique <- bureau_aggregated %>%
#   group_by(SK_ID_CURR) %>%
#  summarize(across(everything(), mean, na.rm = TRUE))  

# Aggregate the previous_application_aggregated data by SK_ID_CURR
# previous_application_aggregated_unique <- previous_application_aggregated %>%
#  group_by(SK_ID_CURR) %>%
#  summarize(across(everything(), mean, na.rm = TRUE))  

# Join bureau_aggregated and previous_application data with application_train
# application_train_combined <- application_train_clean %>%
#  left_join(bureau_aggregated_unique, by = "SK_ID_CURR") %>%
#  left_join(previous_application_aggregated_unique, by = "SK_ID_CURR")



library(data.table)

# Convert data frames to data tables
bureau_aggregated_dt <- as.data.table(bureau_aggregated)
previous_application_aggregated_dt <- as.data.table(previous_application_aggregated)
application_train_clean_dt <- as.data.table(application_train_clean)

# Aggregate the bureau_aggregated data by SK_ID_CURR
bureau_aggregated_unique_dt <- bureau_aggregated_dt[, lapply(.SD, mean, na.rm = TRUE), by = SK_ID_CURR]

# Aggregate the previous_application_aggregated data by SK_ID_CURR
previous_application_aggregated_unique_dt <- previous_application_aggregated_dt[, lapply(.SD, mean, na.rm = TRUE), by = SK_ID_CURR]

# Set keys for faster joins
setkey(application_train_clean_dt, SK_ID_CURR)
setkey(bureau_aggregated_unique_dt, SK_ID_CURR)
setkey(previous_application_aggregated_unique_dt, SK_ID_CURR)

# Perform the join with the `on` argument to specify the join columns
application_train_combined_dt <- application_train_clean_dt[bureau_aggregated_unique_dt, on = "SK_ID_CURR"]
application_train_combined_dt <- application_train_combined_dt[previous_application_aggregated_unique_dt, on = "SK_ID_CURR"]

```

```{r}
library(data.table)

# Convert data frames to data tables
bureau_dt <- as.data.table(bureau)
previous_application_dt <- as.data.table(previous_application)
application_train_clean_dt <- as.data.table(application_train_clean)

# Aggregate bureau data by SK_ID_CURR
bureau_aggregated_dt <- bureau_dt[, .(
  bureau_count = .N,  # Number of records per SK_ID_CURR
  avg_credit_active = mean(CREDIT_ACTIVE == "Active", na.rm = TRUE),  # Proportion of active credits
  total_credit_amt = sum(AMT_CREDIT_SUM, na.rm = TRUE),  # Total credit amount
  avg_days_credit = mean(DAYS_CREDIT, na.rm = TRUE)  # Average days of credit
), by = SK_ID_CURR]

# Aggregate previous_application data by SK_ID_CURR
previous_application_aggregated_dt <- previous_application_dt[, .(
  prev_app_count = .N,  # Number of previous applications
  avg_credit_approved = mean(NAME_CONTRACT_STATUS == "Approved", na.rm = TRUE),  # Proportion of approved applications
  max_amt_credit = max(AMT_CREDIT, na.rm = TRUE),  # Maximum credit amount
  avg_amt_credit = mean(AMT_CREDIT, na.rm = TRUE)  # Average credit amount
), by = SK_ID_CURR]

# Check if 'sk_id_curr' exists in the column names, then rename
if ("sk_id_curr" %in% colnames(application_train_clean_dt)) {
  setnames(application_train_clean_dt, "sk_id_curr", "SK_ID_CURR")
}
# Set keys for faster joins
setkey(application_train_clean_dt, SK_ID_CURR)
setkey(bureau_aggregated_dt, SK_ID_CURR)
setkey(previous_application_aggregated_dt, SK_ID_CURR)

# Perform the joins: Join bureau and previous application data with application_train
application_train_combined_dt <- merge(application_train_clean_dt, bureau_aggregated_dt, by = "SK_ID_CURR", all.x = TRUE)
application_train_combined_dt <- merge(application_train_combined_dt, previous_application_aggregated_dt, by = "SK_ID_CURR", all.x = TRUE)

# Check the result (optional)
head(application_train_combined_dt)
```




## Create New Variables 
```{r}
# 
# Create Binary Variables for ext_source_1, ext_source_2, ext_source_3


# Create new binary variables for ext_source_1, ext_source_2, and ext_source_3
application_train_combined_dt <- application_train_combined_dt %>%
  mutate(
    ext_source_1_binary = ifelse(is.na(ext_source_1), 0, 1),
    ext_source_2_binary = ifelse(is.na(ext_source_2), 0, 1),
    ext_source_3_binary = ifelse(is.na(ext_source_3), 0, 1)
  )

# Verify creation of new binary variables
head(application_train_combined_dt %>% select(ext_source_1, ext_source_1_binary, ext_source_2, ext_source_2_binary, ext_source_3, ext_source_3_binary))

# Create a new variable for debt-to-income ratio
application_train_combined_dt <- application_train_combined_dt %>%
  mutate(debt_to_income_ratio = total_credit_amt / amt_income_total)

# Verify creation of new debt-to-income variables
head(application_train_combined_dt %>% select(total_credit_amt, amt_income_total, debt_to_income_ratio))

# Create a new variable for the ratio of credit card debt to available credit
application_train_combined_dt <- application_train_combined_dt %>%
  mutate(credit_card_debt_ratio = total_credit_amt / max_amt_credit)

# Verify creation of new binary variables
head(application_train_combined_dt %>% select(total_credit_amt, max_amt_credit, credit_card_debt_ratio))

# Calculate Average Credit Score

application_train_combined_dt <- application_train_combined_dt %>%
  mutate(
    average_credit_score = case_when(
      !is.na(ext_source_1) & !is.na(ext_source_2) & !is.na(ext_source_3) ~ (ext_source_1 + ext_source_2 + ext_source_3) / 3,
      !is.na(ext_source_1) & !is.na(ext_source_2) & is.na(ext_source_3) ~ (ext_source_1 + ext_source_2) / 2,
      !is.na(ext_source_1) & is.na(ext_source_2) & !is.na(ext_source_3) ~ (ext_source_1 + ext_source_3) / 2,
      is.na(ext_source_1) & !is.na(ext_source_2) & !is.na(ext_source_3) ~ (ext_source_2 + ext_source_3) / 2,
      !is.na(ext_source_1) & is.na(ext_source_2) & is.na(ext_source_3) ~ ext_source_1,
      is.na(ext_source_1) & !is.na(ext_source_2) & is.na(ext_source_3) ~ ext_source_2,
      is.na(ext_source_1) & is.na(ext_source_2) & !is.na(ext_source_3) ~ ext_source_3,
      TRUE ~ NA_real_  # If all are NA, return NA
    )
  )

head(application_train_combined_dt %>% select(ext_source_1, ext_source_2, ext_source_3, average_credit_score))

# Count the number of NAs in average_credit_score
num_NAs <- sum(is.na(application_train_combined_dt$average_credit_score))

# Print the result
print(num_NAs)

# Check the result (optional)
head(application_train_combined_dt)

```
```{r Logistic regression model}

ls()  # This will list all objects in your environment
str(application_train_combined_dt)


# Load necessary packages
if (!requireNamespace("caTools", quietly = TRUE)) {
  install.packages("caTools")
}
library(caTools)

if (!requireNamespace("pROC", quietly = TRUE)) {
  install.packages("pROC")
}
library(pROC)

if (!requireNamespace("caret", quietly = TRUE)) {
  install.packages("caret")
}
library(caret)


# Splitting the data into training and testing sets (70% training, 30% testing)
set.seed(123)  # Setting seed for reproducibility

split <- sample.split(application_train_combined_dt$target, SplitRatio = 0.7)
train_data <- subset(application_train_combined_dt, split == TRUE)
test_data <- subset(application_train_combined_dt, split == FALSE)



in_train_data <- createDataPartition(train_data$TARGET, p = .1, list = FALSE)






















# Define the formula for logistic regression with specific predictors
formula <- target ~  average_credit_score + days_birth + region_population_relative + debt_to_income_ratio + credit_card_debt_ratio

# Fit the logistic regression model using the training data
logistic_model <- glm(formula, data = train_data, family = binomial)

# Make predictions on the cleaned test set
predicted_prob <- predict(logistic_model, newdata = test_data, type = "response")

# Convert probabilities to binary predictions (0 or 1) using 0.5 as the threshold
predicted_class <- ifelse(predicted_prob > 0.5, 1, 0)

# Confusion matrix (ensure both are the same length)
confusion_matrix <- table(Predicted = predicted_class, Actual = test_data_clean$target)
print(confusion_matrix)

# Compute the ROC curve and AUC value
roc_curve <- roc(test_data$TARGET, predicted_prob)
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))

# Plot ROC curve
plot(roc_curve, main = "ROC Curve for Logistic Regression")

```


 











